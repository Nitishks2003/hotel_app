{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc, roc_auc_score, classification_report, cohen_kappa_score, matthews_corrcoef, precision_recall_curve, average_precision_score, log_loss, brier_score_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: c:\\Users\\User.ACIES35\\Desktop\\project\\src\n"
     ]
    }
   ],
   "source": [
    "working_dir = os.getcwd()\n",
    "print(\"Current Working Directory:\", working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the working directory of the main.py file\n",
    "working_dir = os.path.dirname(os.path.abspath(\"c:/Users/User.ACIES35/Desktop/project/src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the parent directory\n",
    "parent_dir = os.path.dirname(working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User.ACIES35\\Desktop\n"
     ]
    }
   ],
   "source": [
    "print(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Read the data\n",
    "def read_data(file_name):\n",
    "    file_path = f\"{parent_dir}/data/{file_name}\"\n",
    "    if file_path.endswith('.csv'):\n",
    "        df = pd.read_csv(file_path)\n",
    "        return df\n",
    "    elif file_path.endswith('.xlsx') or file_path.endswith('.xls'):\n",
    "        df = pd.read_excel(file_path)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Preprocess the data\n",
    "def preprocess_data(df, target_column, scaler_type):\n",
    "    # Split features and target\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "\n",
    "    # Check if there are only numerical or categorical columns\n",
    "    numerical_cols = X.select_dtypes(include=['number']).columns\n",
    "    categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "    if len(numerical_cols) == 0:\n",
    "        pass\n",
    "    else:\n",
    "        # Split data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Impute missing values for numerical columns (mean imputation)\n",
    "        num_imputer = SimpleImputer(strategy='mean')\n",
    "        X_train[numerical_cols] = num_imputer.fit_transform(X_train[numerical_cols])\n",
    "        X_test[numerical_cols] = num_imputer.transform(X_test[numerical_cols])\n",
    "\n",
    "        # Scale the numerical features based on scaler_type\n",
    "        if scaler_type == 'standard':\n",
    "            scaler = StandardScaler()\n",
    "        elif scaler_type == 'minmax':\n",
    "            scaler = MinMaxScaler()\n",
    "\n",
    "        X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "        X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
    "\n",
    "    if len(categorical_cols) == 0:\n",
    "        pass\n",
    "    else:\n",
    "        # Impute missing values for categorical columns (mode imputation)\n",
    "        cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "        X_train[categorical_cols] = cat_imputer.fit_transform(X_train[categorical_cols])\n",
    "        X_test[categorical_cols] = cat_imputer.transform(X_test[categorical_cols])\n",
    "\n",
    "        # One-hot encode categorical features\n",
    "        encoder = OneHotEncoder()\n",
    "        X_train_encoded = encoder.fit_transform(X_train[categorical_cols])\n",
    "        X_test_encoded = encoder.transform(X_test[categorical_cols])\n",
    "        X_train_encoded = pd.DataFrame(X_train_encoded.toarray(), columns=encoder.get_feature_names(categorical_cols))\n",
    "        X_test_encoded = pd.DataFrame(X_test_encoded.toarray(), columns=encoder.get_feature_names(categorical_cols))\n",
    "        X_train = pd.concat([X_train.drop(columns=categorical_cols), X_train_encoded], axis=1)\n",
    "        X_test = pd.concat([X_test.drop(columns=categorical_cols), X_test_encoded], axis=1)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train the model\n",
    "def train_model(X_train, y_train, model, model_name):\n",
    "    # training the selected model\n",
    "    model.fit(X_train, y_train)\n",
    "    # saving the trained model\n",
    "    with open(f\"{parent_dir}/trained_model/{model_name}.pkl\", 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Evaluate the model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \n",
    "    # Assuming y_score is the predicted probabilities for the positive class\n",
    "    y_score = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Reshape y_score for binary classification\n",
    "    y_score = y_score.reshape(-1, 1)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    kappa = cohen_kappa_score(y_test, y_pred)\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    log_loss_value = log_loss(y_test, y_pred)\n",
    "    brier_score = brier_score_loss(y_test, y_pred)\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "    average_precision = average_precision_score(y_test, y_pred)\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": round(accuracy, 2),\n",
    "        \"confusion_matrix\": conf_matrix,\n",
    "        \"roc_auc\": round(roc_auc, 2),\n",
    "        \"cohen_kappa\": round(kappa, 2),\n",
    "        \"matthews_corrcoef\": round(mcc, 2),\n",
    "        \"classification_report\": class_report,\n",
    "        \"log_loss\": round(log_loss_value, 2),\n",
    "        \"brier_score_loss\": round(brier_score, 2),\n",
    "        \"average_precision\": round(average_precision, 2),\n",
    "        \"precision_recall_curve\": (precision, recall)\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
